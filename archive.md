To make this repository a **Scientific Artifact** (and not just a code dump), these two folders must contain the **Immutable Proof** of your experiments.

Here is exactly what should go in each, along with the code snippets to generate them from your notebooks.

---

### **1. The `models/` Directory**
**Purpose:** The "frozen" brain. This ensures that if a reviewer runs your code, they get the *exact same* diagnosis as the paper, eliminating stochastic training variance.

**Files to Commit:**
1.  **`trm_expert.pth`**: The PyTorch state dictionary of the trained model.
2.  **`config.json`**: The architecture parameters. (Critical: The code needs to know the hidden dimensions to instantiate the model class before loading weights).

**How to Generate Them (Add to end of Notebook 1):**
```python
import json
import os

# 1. Save the Weights
model_path = 'models/trm_expert.pth'
torch.save(physicist.state_dict(), model_path)

# 2. Save the Architecture Config
# This ensures valid reproduction even if you change code defaults later
config = {
    'input_width': 4,
    'hidden_dim': 64,
    'num_classes': 9,
    'prime_rules': [0, 15, 30, 54, 60, 90, 110, 170, 254]
}
with open('models/config.json', 'w') as f:
    json.dump(config, f, indent=4)

print("✅ Brain and Constitution archived in /models/")
```

---

### **2. The `results/` Directory**
**Purpose:** The "Audit Trail." This allows a reviewer to verify your statistics (Table 1) without re-running the expensive 1,000-series loop. It also stores high-resolution figures for the paper.

**Files to Commit:**
1.  **`gauntlet_stats.csv`**: The raw output of Notebook 2. Contains one row per time series with columns: `id`, `dataset`, `true_lag`, `mdl_score`.
2.  **`training_history.csv`**: The loss curve from Notebook 1 (Proof of convergence).
3.  **`figures/` (Subfolder):**
    *   `fig2_lag_distribution.pdf` (Vector graphics are better for LaTeX/Papers).
    *   `fig3_gfc_2008.png`
    *   `fig4_covid_2020.png`
    *   `fig5_ghost_signals.png`

**How to Generate the Stats (Add to end of Notebook 2):**
```python
# Save the DataFrame that generated Table 1
res_df.to_csv('results/gauntlet_stats.csv', index=False)
print("✅ Validation statistics saved to results/gauntlet_stats.csv")

# Save Figure 2 as high-res PDF for the manuscript
plt.figure(figsize=(10, 6))
sns.histplot(...) # Your plotting code
plt.savefig('results/fig2_lag_distribution.pdf', dpi=300, bbox_inches='tight')
```

**How to Generate the Plots (Add to end of Notebook 3):**
```python
# Inside your plotting functions, add:
plt.savefig(f'results/fig_{scenario}_phase_portrait.png', dpi=300, bbox_inches='tight')
```

---

### **3. The `README.md` for these folders**

To look truly professional, add a tiny `README.md` inside each folder explaining what the files are.

**`models/README.md`**:
```markdown
# Model Artifacts

*   **`trm_expert.pth`**: The trained PyTorch weights for the AIT Physicist (Tiny Recursive Model). Calibrated on the "Prime 9" ECA rules.
*   **`config.json`**: Hyperparameters required to instantiate the model architecture.
```

**`results/README.md`**:
```markdown
# Experimental Results

*   **`gauntlet_stats.csv`**: Raw validation metrics for the 40 time series processed in Notebook 2. Used to generate Table 1.
*   **`fig*.pdf/png`**: High-resolution figures generated by the notebooks, used directly in the manuscript.
```

### **Summary Checklist**
1.  **Run Notebook 1** $\rightarrow$ Generates `models/trm_expert.pth` and `models/config.json`.
2.  **Run Notebook 2** $\rightarrow$ Generates `results/gauntlet_stats.csv` and `results/fig2...pdf`.
3.  **Run Notebook 3** $\rightarrow$ Generates `results/fig3...png`, `fig4...png`, `fig5...png`.
4.  **Commit & Push.**

This makes your repository a **self-contained scientific capsule**. Even if you lose the notebooks, the evidence remains.
